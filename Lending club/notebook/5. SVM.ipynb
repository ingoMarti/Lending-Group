{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Son modelos de aprendizaje supervisado con algoritmos de aprendizaje asociados que analizan los datos historicos para el an치lisis de clasificaci칩n y regresi칩n. Sin embargo, se utilizan principalmente en problemas de clasificaci칩n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pandas_profiling\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, recall_score, precision_score, roc_auc_score\n",
    "import pickle\n",
    "from numpy import genfromtxt\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC\n",
    "import scikitplot as skplt\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import model_selection, metrics, linear_model\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as pltimport \n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos el dataset que hemos dejado al final de notebook anterior, despues de hacer el EDA y feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ada = pd.read_csv('../data/X_ada.csv', engine = 'python')\n",
    "y_ada = pd.read_csv('../data/y_ada.csv', engine = 'python')\n",
    "X_test = pd.read_csv('../data/X_test.csv', engine = 'python')\n",
    "y_test = pd.read_csv('../data/y_test.csv', engine = 'python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standarization Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to having 58 variables in our dataset, we need to proceed to standarize our data, to ensure uniformity to certain practices within the industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_ada = scaler.fit_transform(X_ada)\n",
    "X_test= scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM or Support Vector Machine is a linear model for classification and regression problems. It can solve linear and non-linear problems and work well for many practical problems. The idea of SVM is simple: The algorithm creates a line or a hyperplane which separates the data into classes.\n",
    "\n",
    "According to the SVM algorithm we find the points closest to the line from both the classes.These points are called support vectors. Now, we compute the distance between the line and the support vectors. This distance is called the margin. Our goal is to maximize the margin. The hyperplane for which the margin is maximum is the optimal hyperplane.\n",
    "\n",
    "Thus SVM tries to make a decision boundary in such a way that the separation between the two classes(that street) is as wide as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=123)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm = SVC(random_state = 123)\n",
    "clf_svm.fit(X_ada, y_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed with the prediction base on the model we just built, and to calculate the following indicators:\n",
    "\n",
    " - Confusion Matrix\n",
    " - Accuracy score.\n",
    " - Recall Score.\n",
    " - Precision.\n",
    " - Roc Auc score.\n",
    " - F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_class = clf_svm.predict(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confussion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20275,   161],\n",
       "       [15421, 47011]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1a2ebf015e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, y_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to our confussion Matrix we can interpretate the following:\n",
    "\n",
    " - 20.275 True Negatives. We have predicted \"Charged Off\" and in real they are \"Charged Off\".\n",
    " - 161 False Positives. We have predicted \"Fully Paid\" in reality \"Charged Off\".\n",
    " - 15.421 Flase Negatives. We have predicted \"Charge Off\" in reality \"Full Paid\".\n",
    " - 47.011 True Postives. We have predicted \"Fully Paid\" and in real they are \"Fully Paid\".\n",
    "\n",
    "Of a total sample of 81.890 observations our model has predicted wrong 15.582, which is a 19% of the total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.811966018245885"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this model we were able to obtain a 81,90% of accuracy, which means if we have 100 observation we are able to predict altmost 82% right. The issue with this score is when our model is imbalanced, meaning this score can deceive us into believing that a bad model is a good model. So to be certain we are going to use the balanced_accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8725585023900797"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_test, y_class, sample_weight=None, adjusted=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall Score & Precision Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7529952588416197"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratio is number of true positives/(true positives + false negatives), it informs us about the quantity that our model can predict being 1 the best value and 0 the worst values, in our case we have obtain an outstanding result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We measure the quality of our model, the formula is TruePositive/(TruePositives+FalsePositives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9965869583651319"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision is intuitively the ability of the classifier not to label as positive a sample that is negative being best value 1 and worst value 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have obtain a rather unusual Recall & Precision score, normally this scores have an inverse correlation, so how is it possible to have obtain a rather great scores, several reasons:\n",
    "\n",
    " - Imbalanced Sample.\n",
    " - We have missed important variables in our selection.\n",
    " - Our model is so train that is bias towards certain results.\n",
    " - We have created a great model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Precision-Recall\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "precision, recall, _= precision_recall_curve(y_test, y_class)\n",
    "plt.step(recall, precision, color='g', alpha=0.2, where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='g', step='post')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall curve')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1score (a, b):\n",
    "    return (precision_score(y_test, y_class)*recall_score(y_test, y_class))/(precision_score(y_test, y_class)+recall_score(y_test, y_class))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42891682785299806"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1score(y_test, y_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our f1 score show us that the mean between the precision score and the recall score, being a 45% we consider is a good result and our model focueses both in recall and precision, so if we wanted to increase one over the other there would not be any inconvineance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Roc Auc Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC is created by the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings. The true-positive rate is also known as sensitivity, recall or probability of detection in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8725585023900797"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The roc curve shows us in a simple way the probability that our model clasifies a random observation into a TP rahter that FP in diferent thresholds. Our AUC is 80%, which means that are predictions are 80% correct. However, in this particular case we want to identify as much False positives as possible, as they are people who are not going to receive the loan, when in reality they should recieve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results of our SVM\n",
      "accuracy score 0.811966018245885\n",
      "balanced accuracy score 0.8725585023900797\n",
      "recall score 0.7529952588416197\n",
      "precision score 0.9965869583651319\n",
      "roc auc score 0.8725585023900797\n"
     ]
    }
   ],
   "source": [
    "print(\"The results of our SVM\")\n",
    "\n",
    "\n",
    "print(\"accuracy score\", accuracy_score(y_test, y_class))\n",
    "print(\"balanced accuracy score\", balanced_accuracy_score(y_test, y_class))\n",
    "print(\"recall score\", recall_score(y_test, y_class))\n",
    "print(\"precision score\", precision_score(y_test, y_class))\n",
    "print(\"roc auc score\", roc_auc_score(y_test, y_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf_svm, open(\"svm\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reviewing several of the results we have concluded the following:\n",
    "\n",
    "    1) Our dataset is imbalance so the results we have obtain are normal because they are biased.\n",
    "    2) Our model is so train that the bias affects our results.\n",
    "    3) During the selection of the variables we have add or remove important variable that affect the results.\n",
    "    4) We have built a very robust and precise model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "To built our model we have search many sources of informaction through the internet.\n",
    "\n",
    "https://towardsdatascience.com/dont-sweat-the-solver-stuff-aea7cddc3451 # parameters\n",
    "\n",
    "https://scikit-learn.org/stable/modules/naive_bayes.html # naive model\n",
    "\n",
    "https://towardsdatascience.com/tagged/scikit-learn # sk\n",
    "\n",
    "https://medium.com/vickdata/a-simple-guide-to-scikit-learn-pipelines-4ac0d974bdcf # pipelines\n",
    "\n",
    "https://medium.com/@benfenison/gridsearching-a-random-forest-classifier-fc225609699c # rf\n",
    "\n",
    "https://medium.com/fintechexplained/how-to-save-trained-machine-learning-models-649c3ad1c018 # pickle\n",
    "\n",
    "https://machinelearningmastery.com/rfe-feature-selection-in-python/ # feature engineering\n",
    "\n",
    "https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c # precision and recall\n",
    "\n",
    "https://towardsdatascience.com/meaningful-metrics-cumulative-gains-and-lyft-charts-7aac02fc5c14 # cumulative gain\n",
    "\n",
    "https://towardsdatascience.com/evaluate-model-performance-with-cumulative-gains-and-lift-curves-1f3f8f79da01 # cumulative gain\n",
    "\n",
    "https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/#:~:text=true%20positives%20(TP)%3A%20These,they%20do%20have%20the%20disease.&text=false%20positives%20(FP)%3A%20We,actually%20do%20have%20the%20disease. # confusion matrix\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c# roc curve\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LG",
   "language": "python",
   "name": "lendinggroup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
